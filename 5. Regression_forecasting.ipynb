{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прогнозирование с помощью регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "Класс моделей ARIMA недостаточно богат для наших данных: с их помощью, например, никак нельзя учесть взаимосвязи между рядами. Это можно сделать с помощью векторной авторегрессии VARIMA, но её питоновская реализация не позволяет использовать регрессионные признаки. Кроме того, авторегрессионный подход не позволяет учитывать, например, взаимодействия между сезонными компонентами. Вы могли заметить, что форма суточных сезонных профилей в будни и выходные немного разная; явно моделировать этот эффект с помощью ARIMA не получится.\n",
    "\n",
    "Нам нужна более сложная модель. Давайте займёмся сведением задачи массового прогнозирования рядов к регрессионной постановке!\n",
    "\n",
    "Вам понадобится много признаков. Некоторые из них у вас уже есть — это:\n",
    "\n",
    "- идентификатор географической зоны\n",
    "- дата и время\n",
    "- количество поездок в периоды, предшествующие прогнозируемому\n",
    "- синусы, косинусы и тренды, которые вы использовали внутри регрессионной компоненты ARIMA\n",
    "\n",
    "Кроме того, не спешите выбрасывать построенный вами на прошлой неделе прогнозы — из них может получиться хороший признак для регрессии!\n",
    "\n",
    "Вы можете попробовать разные регрессионный модели, но хорошие результаты, скорее всего, дадут такие, которые будут позволять признакам взаимодействовать друг с другом.\n",
    "\n",
    "Поскольку прогноз нужен на 6 часов вперёд, проще всего будет построить 6 независимых регрессионных моделей — одна для прогнозирования $ \\widehat{y}_{T+1|T} $, другая для $ \\widehat{y}_{T+2|T} $ и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание № 1\n",
    "\n",
    "Для каждой из шести задач прогнозирования $ \\widehat{y}_{T+i|T} ,i=1,…,6 $ сформируйте выборки. Откликом будет $ y_{T+i} $ при всевозможных значениях $ T $, а признаки можно использовать следующие:\n",
    "- идентификатор географической зоны — категориальный\n",
    "- год, месяц, день месяца, день недели, час — эти признаки можно пробовать брать и категориальными, и непрерывными, можно даже и так, и так\n",
    "- синусы, косинусы и тренды, которые вы использовали внутри регрессионной компоненты ARIMA\n",
    "- сами значения прогнозов ARIMA $ \\widehat{y}^{ARIMA}_{T+i|T} $\n",
    "- количество поездок из рассматриваемого района в моменты времени $ y_T,y_{T−1},…,y_{T−K} $(параметр $K$ можно подбирать; попробуйте начать, например, с 6)\n",
    "- количество поездок из рассматриваемого района в моменты времени $ y_{T−24} ,y_{T−48},…,y_{T−24∗K_d} $ (параметр $K_d$ можно подбирать; попробуйте начать, например, с 2)\n",
    "- суммарное количество поездок из рассматриваемого района за предшествующие полдня, сутки, неделю, месяц\n",
    "\n",
    "Будьте внимательны при создании признаков — все факторы должны быть рассчитаны без использования информации из будущего: при прогнозировании $ \\widehat{y}_{T+i|T} ,i=1,…,6 $ вы можете учитывать только значения $ y $ до момента времени $ T $ включительно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ar4eBaT/anaconda/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед созданием признаков необходимо загрузить данные, и совместить их между собой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = glob(\"u_data/*.csv\", recursive=True)\n",
    "file_path = np.sort(file_path)[:-12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_data(path):\n",
    "    data_list = []\n",
    "    for p in path:\n",
    "        data = pd.read_csv(p, sep=\",\", index_col=\"time\", parse_dates=[\"time\"])\n",
    "        data_list.append(data)\n",
    "    return pd.concat(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_orig = open_data(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_means = data_orig.loc['2016.05.01 00:00:00':'2016.05.31 23:00:00'].groupby(\"region\").mean()\n",
    "regions = data_means[data_means.trips >= 5].index.values\n",
    "del data_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_check = data_orig.region.isin(regions)\n",
    "data = data_orig[regions_check].loc['2013.01.01 00:00:00':'2016.06.30 23:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_1075</th>\n",
       "      <th>region_1076</th>\n",
       "      <th>region_1077</th>\n",
       "      <th>region_1125</th>\n",
       "      <th>region_1126</th>\n",
       "      <th>region_1127</th>\n",
       "      <th>region_1128</th>\n",
       "      <th>region_1129</th>\n",
       "      <th>region_1130</th>\n",
       "      <th>region_1131</th>\n",
       "      <th>...</th>\n",
       "      <th>region_1630</th>\n",
       "      <th>region_1684</th>\n",
       "      <th>region_1733</th>\n",
       "      <th>region_1734</th>\n",
       "      <th>region_1783</th>\n",
       "      <th>region_2068</th>\n",
       "      <th>region_2069</th>\n",
       "      <th>region_2118</th>\n",
       "      <th>region_2119</th>\n",
       "      <th>region_2168</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01 00:00:00</th>\n",
       "      <td>75.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>538.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>769.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01 01:00:00</th>\n",
       "      <td>108.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>572.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>623.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01 02:00:00</th>\n",
       "      <td>82.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>484.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01 03:00:00</th>\n",
       "      <td>79.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01 04:00:00</th>\n",
       "      <td>35.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     region_1075  region_1076  region_1077  region_1125  \\\n",
       "time                                                                      \n",
       "2013-01-01 00:00:00         75.0        149.0         88.0         95.0   \n",
       "2013-01-01 01:00:00        108.0        204.0         81.0        126.0   \n",
       "2013-01-01 02:00:00         82.0        162.0         83.0        135.0   \n",
       "2013-01-01 03:00:00         79.0        122.0         24.0        106.0   \n",
       "2013-01-01 04:00:00         35.0         89.0         20.0         59.0   \n",
       "\n",
       "                     region_1126  region_1127  region_1128  region_1129  \\\n",
       "time                                                                      \n",
       "2013-01-01 00:00:00        297.0        538.0        594.0        769.0   \n",
       "2013-01-01 01:00:00        402.0        572.0        518.0        623.0   \n",
       "2013-01-01 02:00:00        361.0        471.0        470.0        495.0   \n",
       "2013-01-01 03:00:00        289.0        482.0        448.0        467.0   \n",
       "2013-01-01 04:00:00        181.0        332.0        377.0        343.0   \n",
       "\n",
       "                     region_1130  region_1131     ...       region_1630  \\\n",
       "time                                              ...                     \n",
       "2013-01-01 00:00:00        952.0        267.0     ...              12.0   \n",
       "2013-01-01 01:00:00        655.0        220.0     ...              22.0   \n",
       "2013-01-01 02:00:00        484.0        156.0     ...              23.0   \n",
       "2013-01-01 03:00:00        337.0        102.0     ...              25.0   \n",
       "2013-01-01 04:00:00        354.0         92.0     ...              26.0   \n",
       "\n",
       "                     region_1684  region_1733  region_1734  region_1783  \\\n",
       "time                                                                      \n",
       "2013-01-01 00:00:00          0.0          9.0        113.0         27.0   \n",
       "2013-01-01 01:00:00          0.0          3.0          7.0          5.0   \n",
       "2013-01-01 02:00:00          0.0          1.0          6.0          3.0   \n",
       "2013-01-01 03:00:00          0.0          1.0          1.0          7.0   \n",
       "2013-01-01 04:00:00          0.0          2.0          5.0          2.0   \n",
       "\n",
       "                     region_2068  region_2069  region_2118  region_2119  \\\n",
       "time                                                                      \n",
       "2013-01-01 00:00:00         19.0          6.0         68.0         18.0   \n",
       "2013-01-01 01:00:00         11.0          3.0         82.0          1.0   \n",
       "2013-01-01 02:00:00          2.0          0.0         28.0          0.0   \n",
       "2013-01-01 03:00:00          2.0          0.0          6.0          0.0   \n",
       "2013-01-01 04:00:00          3.0          0.0         30.0          2.0   \n",
       "\n",
       "                     region_2168  \n",
       "time                              \n",
       "2013-01-01 00:00:00         67.0  \n",
       "2013-01-01 01:00:00         15.0  \n",
       "2013-01-01 02:00:00         16.0  \n",
       "2013-01-01 03:00:00          1.0  \n",
       "2013-01-01 04:00:00         16.0  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = [data[data.region == r].trips for r in regions]\n",
    "data = pd.concat(temp, axis=1)\n",
    "data.columns = [\"region_\" + str(region) for region in regions]\n",
    "del temp\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем признаковое пространство из значений года, месяца, дня и часа, разделяя значения дат и времени у исходной выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_0 = (['region_1175', 'region_1337', 'region_1338', 'region_1339', 'region_1386', 'region_1442'], (6, 12))\n",
    "cluster_1 = (['region_1129', 'region_1130', 'region_1176', 'region_1177', 'region_1178', 'region_1227',\n",
    "             'region_1228', 'region_1278'], (4, 14))\n",
    "cluster_2 = (['region_1127', 'region_1128', 'region_1131', 'region_1179', 'region_1182', 'region_1224',\n",
    "             'region_1229', 'region_1230'], (6, 10))\n",
    "cluster_3 = (['region_1076', 'region_1077', 'region_1132', 'region_1181', 'region_1183', 'region_1184',\n",
    "             'region_1234', 'region_1235', 'region_1279', 'region_1280', 'region_1284', 'region_1285',\n",
    "             'region_1286', 'region_1287', 'region_1331', 'region_1332', 'region_1333', 'region_1334',\n",
    "             'region_1335', 'region_1336', 'region_1383', 'region_1384', 'region_1385', 'region_1434'], (5, 12))\n",
    "cluster_4 = (['region_1480', 'region_1483', 'region_1530', 'region_1580'], (6, 9))\n",
    "cluster_5 = (['region_1075', 'region_1125', 'region_1126', 'region_1180', 'region_1231', 'region_1232',\n",
    "             'region_1233', 'region_1281', 'region_1282', 'region_1283', 'region_1382'], (6, 13))\n",
    "cluster_6 = (['region_1172', 'region_1173', 'region_1174', 'region_1225'], (6, 15))\n",
    "cluster_7 = (['region_1326', 'region_1327', 'region_1376', 'region_1377', 'region_1378', 'region_1426'], (6, 5))\n",
    "cluster_8 = (['region_2168'], (4, 10))\n",
    "cluster_9 = (['region_1221', 'region_1222', 'region_1223', 'region_1272', 'region_1273', 'region_1274',\n",
    "             'region_1380'], (6, 4))\n",
    "cluster_10 = (['region_1389', 'region_1390', 'region_1439'], (4, 7))\n",
    "cluster_11 = (['region_2068', 'region_2069', 'region_2118', 'region_2119'], (6, 5))\n",
    "cluster_12 = (['region_1684', 'region_1733', 'region_1734', 'region_1783'], (6, 4))\n",
    "cluster_13 = (['region_1431'], (6, 3))\n",
    "cluster_14 = (['region_1387', 'region_1388', 'region_1435', 'region_1436', 'region_1437', 'region_1438'], (3, 7))\n",
    "cluster_15 = (['region_1630'], (6, 3))\n",
    "cluster_16 = (['region_1482', 'region_1532', 'region_1533'], (6, 1))\n",
    "cluster_17 = (['region_1441'], (5, 3))\n",
    "\n",
    "clusters = [cluster_0, cluster_1, cluster_2, cluster_3, cluster_4, cluster_5, cluster_6, cluster_7, cluster_8,\n",
    "           cluster_9, cluster_10, cluster_11, cluster_12, cluster_13, cluster_14, cluster_15, cluster_16,\n",
    "            cluster_17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция построения регрессионного признака по формулам синуса и косинуса\n",
    "\n",
    "def season_attribute(func_name, start_T, T, season_length, season_name, K):\n",
    "    if func_name not in [\"sin\", \"cos\"]:\n",
    "        raise ValueError(\"Set func_name the value is sin or cos\")\n",
    "    \n",
    "    func = np.sin if func_name is \"sin\" else np.cos\n",
    "    \n",
    "    if start_T < 1:\n",
    "        raise ValueError(\"Set start_T equal or greater then 1\")\n",
    "        \n",
    "    t_interval = np.arange(start_T, T + 1, dtype=int)\n",
    "    values_dict = dict()\n",
    "    for k in range(1, K + 1):\n",
    "        key = func_name + \"_\" + season_name + \"_\" + str(k)\n",
    "        values_dict[key] = func(t_interval * 2 * np.pi * k / season_length)\n",
    "    return pd.DataFrame(values_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция создания признака тренда\n",
    "\n",
    "def trend_attribute(start_T, T):\n",
    "    if start_T < 1:\n",
    "        raise ValueError(\"Set start_T equal or greater then 1\")  \n",
    "    t_interval = np.arange(start_T, T + 1, dtype=int)\n",
    "    return pd.DataFrame(t_interval, columns=[\"Trend\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция построения значений ряда Фурье по значениям k для недели и года.\n",
    "\n",
    "def set_attributes(cluster, week_k=0, year_k=0, trend=True, start=1, end=1):\n",
    "    data_list = []\n",
    "    \n",
    "    if cluster is not None:\n",
    "        data_list.extend([cluster])\n",
    "    \n",
    "    if end <= 1:\n",
    "        end = cluster.shape[0]\n",
    "    \n",
    "    day_hours = 24\n",
    "\n",
    "    # Регрессионные признаки по недельной сезонности\n",
    "    week_hours = day_hours * 7\n",
    "    if week_k > 0:\n",
    "        sin_week_data = season_attribute(\"sin\", start, end, week_hours, \"week\", week_k).set_index(cluster.index)\n",
    "        cos_week_data = season_attribute(\"cos\", start, end, week_hours, \"week\", week_k).set_index(cluster.index)\n",
    "        data_list.extend([sin_week_data, cos_week_data])\n",
    "\n",
    "    # Регрессионные признаки по годовой сезонности\n",
    "    year_hours = 8766\n",
    "    if year_k > 0:\n",
    "        sin_year_data = season_attribute(\"sin\", start, end, year_hours, \"year\", year_k).set_index(cluster.index)\n",
    "        cos_year_data = season_attribute(\"cos\", start, end, year_hours, \"year\", year_k).set_index(cluster.index)\n",
    "        data_list.extend([sin_year_data, cos_year_data])\n",
    "    \n",
    "    if trend is True:\n",
    "        trend_data = trend_attribute(start, end).set_index(cluster.index)\n",
    "        data_list.extend([trend_data])\n",
    "\n",
    "    cluster = pd.concat(data_list, axis=1)\n",
    "        \n",
    "    return cluster.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение параметров региона для построения признакового пространства из значений ряда Фурье, в зависимости от\n",
    "# принадлежности региона к какому-либо из кластеров\n",
    "\n",
    "def get_params(region):\n",
    "    for cluster in clusters:\n",
    "        if region in cluster[0]:\n",
    "            return cluster[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция получения значений поездок за предыдущие k-часов\n",
    "\n",
    "def trips_short(region, k):\n",
    "    trips = np.zeros((data.shape[0]-k-1, k+1))\n",
    "    for i in range(k+1, data.shape[0]):\n",
    "        trips[i-k-1] = data[region].iloc[i-k-1:i][::-1].get_values()\n",
    "    \n",
    "    columns = [\"trips_short_t\"]\n",
    "    columns.extend(list(map(lambda num: \"trips_short_t_\" + str(num), range(1, k+1))))\n",
    "    \n",
    "    return pd.DataFrame(trips, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция получения значение поездок за предыдущие k-дней\n",
    "\n",
    "def trips_days(region, k):\n",
    "    trips = np.zeros((data.shape[0]-24*k, k))\n",
    "    for i in range(24*k, data.shape[0]):\n",
    "        trips[i-24*k] = list(map(lambda num: data[region].iloc[i - 24*(num+1)], range(k)))\n",
    "    \n",
    "    columns = []\n",
    "    columns.extend(list(map(lambda num: \"trips_days_t_\" + str(24*num), range(1, k+1))))\n",
    "    \n",
    "    return pd.DataFrame(trips, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция получения суммы поездок за указанный период\n",
    "\n",
    "def count_trips(region, period):\n",
    "    ct_hd = np.zeros(data.shape[0])\n",
    "    for i in range(data.shape[0]):\n",
    "        if i is 0:\n",
    "            ct_hd[i] = data[region].iloc[0]\n",
    "        elif i < period:\n",
    "            ct_hd[i] = data[region].iloc[:i+1].sum()\n",
    "        else:\n",
    "            ct_hd[i] = data[region].iloc[i-period:i+1].sum()\n",
    "    return ct_hd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция построения признаковых пространств по суммам за период половины суток, суток, недели и месяца\n",
    "\n",
    "def all_count_trips(region):\n",
    "    count_trips_params = [(\"count_trips_semiday\", 12), (\"count_trips_allday\", 24), (\"count_trips_week\", 24*7),\n",
    "                         (\"count_trips_month\", 24*30)]\n",
    "    ct_list = []\n",
    "    columns = []\n",
    "    for params in count_trips_params:\n",
    "        ct_list.append(count_trips(region, params[1]))\n",
    "        columns.append(params[0])\n",
    "    \n",
    "    ct_list = np.array(ct_list).transpose()\n",
    "    return pd.DataFrame(ct_list, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция, объединяющая вышеопределенные, для построения признакового пространства заданного региона\n",
    "\n",
    "def create_attributes(sin_cos, k_sh, k_days):\n",
    "    region = sin_cos.region[0]\n",
    "\n",
    "    date_attrib = []\n",
    "    for date in data.index:\n",
    "        date_attrib.append([date.year, date.strftime(\"%B\"), date.day, date.weekday_name, date.hour])\n",
    "    date_attrib = pd.DataFrame(date_attrib, columns=[\"year\", \"month\", \"day\", \"dayofweek\", \"hour\"])\n",
    "    t_sh = trips_short(region, k_sh)\n",
    "    t_days = trips_days(region, k_days)\n",
    "    c_t = all_count_trips(region)\n",
    "\n",
    "    min_val_count = np.min([date_attrib.shape[0], t_sh.shape[0], t_days.shape[0], c_t.shape[0]])\n",
    "    \n",
    "    date_attrib = date_attrib.iloc[-min_val_count:]\n",
    "    date_attrib.index = range(min_val_count)\n",
    "    \n",
    "    t_sh = t_sh.iloc[-min_val_count:]\n",
    "    t_sh.index = range(min_val_count)\n",
    "    \n",
    "    t_days = t_days.iloc[-min_val_count:]\n",
    "    t_days.index = range(min_val_count)\n",
    "    \n",
    "    c_t = c_t.iloc[-min_val_count:]\n",
    "    c_t.index = range(min_val_count)\n",
    "    \n",
    "    sin_cos = sin_cos.iloc[-min_val_count:]\n",
    "    sin_cos.index = range(min_val_count)\n",
    "    \n",
    "    res_data = [date_attrib, sin_cos, t_sh, t_days, c_t]\n",
    "    all_data = pd.concat(res_data, axis=1)\n",
    "    \n",
    "    data_list = []\n",
    "    for k in range(1, 7):\n",
    "        target = data[region].iloc[-min_val_count+k:]\n",
    "        target = pd.DataFrame(target.get_values(), index=range(len(target)), columns=[\"trips\"])\n",
    "        data_list.append(pd.concat([target, all_data[:-k]], axis=1))\n",
    "    return (data_list[0], data_list[1], data_list[2], data_list[3], data_list[4], data_list[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция выполняющая подготовку признаков, и применяет последовательное ранжирования для данных каждой из задач\n",
    "\n",
    "def prepare_data(k_sh, k_days):\n",
    "    attr_sin_cos = []\n",
    "    for region in data.columns:\n",
    "        params = get_params(region)\n",
    "        attr = set_attributes(data[region], params[0], params[1])\n",
    "        region_df = pd.DataFrame(np.repeat(region, data.shape[0]), index=attr.index, columns=[\"region\"], dtype=\"category\")\n",
    "        attr_sin_cos.append(pd.concat([region_df, attr], axis=1))\n",
    "    \n",
    "    first_data = []\n",
    "    second_data = []\n",
    "    third_data = []\n",
    "    fourth_data = []\n",
    "    fifth_data = []\n",
    "    sixth_data = []\n",
    "    for sin_cos in attr_sin_cos:\n",
    "        data_list = create_attributes(sin_cos, k_sh, k_days)\n",
    "        first_data.append(data_list[0])\n",
    "        second_data.append(data_list[1])\n",
    "        third_data.append(data_list[2])\n",
    "        fourth_data.append(data_list[3])\n",
    "        fifth_data.append(data_list[4])\n",
    "        sixth_data.append(data_list[5])\n",
    "    \n",
    "    first_data = pd.concat(first_data).fillna(0.0).sort_values([\"year\", \"month\", \"day\", \"hour\"])\n",
    "    second_data = pd.concat(second_data).fillna(0.0).sort_values([\"year\", \"month\", \"day\", \"hour\"])\n",
    "    third_data = pd.concat(third_data).fillna(0.0).sort_values([\"year\", \"month\", \"day\", \"hour\"])\n",
    "    fourth_data = pd.concat(fourth_data).fillna(0.0).sort_values([\"year\", \"month\", \"day\", \"hour\"])\n",
    "    fifth_data = pd.concat(fifth_data).fillna(0.0).sort_values([\"year\", \"month\", \"day\", \"hour\"])\n",
    "    sixth_data = pd.concat(sixth_data).fillna(0.0).sort_values([\"year\", \"month\", \"day\", \"hour\"])\n",
    "    \n",
    "    return (first_data, second_data, third_data, fourth_data, fifth_data, sixth_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для достаточной полноты данных было принято решение указать значение **k-часов** равным 24, а **k-суток** равным двум неделям.\n",
    "\n",
    "Далее осуществляется подготовка данных, и сохранение их на компьютере."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "first_data, second_data, third_data, fourth_data, fifth_data, sixth_data = prepare_data(24, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_data.to_csv(\"new_data/1. First_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_data.to_csv(\"new_data/2. Second_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_data.to_csv(\"new_data/3. Third_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth_data.to_csv(\"new_data/4. Fourth_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifth_data.to_csv(\"new_data/5. Fifth_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sixth_data.to_csv(\"new_data/6. Sixth_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание № 2\n",
    "\n",
    "Разбейте каждую из шести выборок на три части:\n",
    "\n",
    "- обучающая, на которой будут настраиваться параметры моделей — всё до апреля 2016\n",
    "- тестовая, на которой вы будете подбирать значения гиперпараметров — май 2016\n",
    "- итоговая, которая не будет использоваться при настройке моделей вообще — июнь 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция разделения единого массива данных на обучающую, тестовую и контрольную выборки\n",
    "\n",
    "def split_data(input_data):\n",
    "    train_data = pd.concat([input_data[input_data.year < 2016],\n",
    "                            input_data[(input_data.year == 2016) & (input_data.month.astype(int) < 5)]])\n",
    "\n",
    "    test_data = input_data[(input_data.year == 2016) & (input_data.month == \"5\")]\n",
    "    control_data = pd.concat([test_data[-102:],\n",
    "                             input_data[(input_data.year == 2016) & (input_data.month == \"6\")]])\n",
    "    test_data = test_data[:-102]\n",
    "    \n",
    "    return train_data, test_data, control_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном этапе происходит разделение данных из каждой задачи на три выборки, и сохраняет полученный кортеж в общем массиве."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = np.sort(glob(\"new_data/*.csv\", recursive=True))\n",
    "input_data = []\n",
    "for path in file_path:\n",
    "    new_data = pd.read_csv(path)\n",
    "    new_data.month = new_data.month.astype(str)\n",
    "    input_data.append(new_data)\n",
    "    \n",
    "result_data = []\n",
    "for i in range(len(input_data)):\n",
    "    i_data = input_data[i]\n",
    "    result_data.append(split_data(i_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание № 3\n",
    "\n",
    "Выберите вашу любимую регрессионную модель и настройте её на каждом из шести наборов данных, подбирая гиперпараметры на мае 2016. Желательно, чтобы модель:\n",
    "\n",
    "- допускала попарные взаимодействия между признаками\n",
    "- была устойчивой к избыточному количеству признаков (например, использовала регуляризаторы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание массива названий столбцов признаков, за исключением признаков значений года и дня, по причине их незначительного влияния на конечную модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trips ~ Trend + cos_week_1 + cos_week_2 + cos_week_3 + cos_week_4 + cos_week_5 + cos_week_6 + cos_year_1 + cos_year_10 + cos_year_11 + cos_year_12 + cos_year_13 + cos_year_14 + cos_year_15 + cos_year_2 + cos_year_3 + cos_year_4 + cos_year_5 + cos_year_6 + cos_year_7 + cos_year_8 + cos_year_9 + count_trips_allday + count_trips_month + count_trips_semiday + count_trips_week + dayofweek + hour + month + region + sin_week_1 + sin_week_2 + sin_week_3 + sin_week_4 + sin_week_5 + sin_week_6 + sin_year_1 + sin_year_10 + sin_year_11 + sin_year_12 + sin_year_13 + sin_year_14 + sin_year_15 + sin_year_2 + sin_year_3 + sin_year_4 + sin_year_5 + sin_year_6 + sin_year_7 + sin_year_8 + sin_year_9 + trips_days_t_120 + trips_days_t_144 + trips_days_t_168 + trips_days_t_192 + trips_days_t_216 + trips_days_t_24 + trips_days_t_240 + trips_days_t_264 + trips_days_t_288 + trips_days_t_312 + trips_days_t_336 + trips_days_t_48 + trips_days_t_72 + trips_days_t_96 + trips_short_t + trips_short_t_1 + trips_short_t_10 + trips_short_t_11 + trips_short_t_12 + trips_short_t_13 + trips_short_t_14 + trips_short_t_15 + trips_short_t_16 + trips_short_t_17 + trips_short_t_18 + trips_short_t_19 + trips_short_t_2 + trips_short_t_20 + trips_short_t_21 + trips_short_t_22 + trips_short_t_23 + trips_short_t_24 + trips_short_t_3 + trips_short_t_4 + trips_short_t_5 + trips_short_t_6 + trips_short_t_7 + trips_short_t_8 + trips_short_t_9'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribute_cols = input_data[0].columns[(input_data[0].columns != \"trips\") & (input_data[0].columns != \"year\") & (input_data[0].columns != \"day\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве модели, осуществляющей прогноз поездок по районам, был выбран **Случайный лес**, так как он позволяет признакам тесно взаимодейсвовать между собой.\n",
    "\n",
    "Перед обучением модели, следует к категориальным признакам применить **бинарное кодирование**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_extraction import DictVectorizer as DV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_attributes = [\"region\", \"month\", \"dayofweek\"]\n",
    "regions = pd.unique(result_data[0][0][\"region\"])\n",
    "month = list(map(lambda x: \"m_\" + str(x), (pd.unique(result_data[0][0][\"month\"]))))\n",
    "dayofweek = pd.unique(result_data[0][0][\"dayofweek\"])\n",
    "cat_columns = np.append(np.append(regions, month), dayofweek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = DV(sparse = False)\n",
    "encoder.fit(result_data[0][0][cat_attributes].T.to_dict().values())\n",
    "cat_att = pd.DataFrame(encoded_data, columns=cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(attribute_cols)\n",
    "a.remove(\"month\")\n",
    "a.remove('dayofweek')\n",
    "a.remove('hour')\n",
    "a.remove('region')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе обучения модели была сразу проведена предварительная оценка качества результата обучения алгорима на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.23648809997612\n",
      "19.09034466289899\n",
      "19.39166600334315\n",
      "19.88454190877975\n",
      "19.952307039189154\n",
      "20.01525644087134\n",
      "CPU times: user 6h 11min 32s, sys: 4min 44s, total: 6h 16min 16s\n",
      "Wall time: 6h 17min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "results = []\n",
    "for data in result_data:\n",
    "    estimator = RandomForestRegressor()\n",
    "\n",
    "    encoded_data = encoder.transform(data[0][cat_attributes].T.to_dict().values())\n",
    "    cat_att = pd.DataFrame(encoded_data, columns=cat_columns)\n",
    "    cat_att.index = data[0][a].index\n",
    "\n",
    "    X_train = pd.concat([data[0][a], cat_att], axis=1)\n",
    "    y_train = data[0][\"trips\"]\n",
    "\n",
    "    fitted = estimator.fit(X_train, y_train)\n",
    "\n",
    "    encoded_data = encoder.transform(data[1][cat_attributes].T.to_dict().values())\n",
    "    cat_att = pd.DataFrame(encoded_data, columns=cat_columns)\n",
    "    cat_att.index = data[1][a].index\n",
    "\n",
    "    X_test = pd.concat([data[1][a], cat_att], axis=1)\n",
    "    y_test = data[1][\"trips\"]\n",
    "\n",
    "    prediction = fitted.predict(X_test)\n",
    "    estimate = sum(np.abs(prediction.astype(int) - y_test)) / (102 * 739)\n",
    "    \n",
    "    results.append((fitted, estimate))\n",
    "    print(estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание № 4\n",
    "\n",
    "Выбранными моделями постройте для каждой географической зоны и каждого конца истории от 2016.04.30 23:00 до 2016.05.31 17:00 прогнозы на 6 часов вперёд; посчитайте в ноутбуке ошибку прогноза по следующему функционалу:\n",
    "\n",
    "<center>$Q_{june}=\\frac{1}{R∗739∗6}\\sum_{r=1}^R\\sum_{T=2016.05.01-00:00}^{T=2016.05.31-23:00}\\sum_{i=1}^6\\mid{\\widehat{y}}^r_{T|T+i}−{\\widehat{y}}^r_{T+i}\\mid.$</center>\n",
    "\n",
    "Убедитесь, что ошибка полученных прогнозов, рассчитанная согласно функционалу Q, определённому на прошлой неделе, уменьшилась по сравнению с той, которую вы получили методом индивидуального применения моделей ARIMA. Если этого не произошло, попробуйте улучшить ваши модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае, нам остается просуммировать оценки, полученные ранее, и разделить на количество задач."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.428434025843085\n"
     ]
    }
   ],
   "source": [
    "estimate = 0\n",
    "for i in range(6):\n",
    "    estimate += results[i][1]\n",
    "print(estimate / 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученный результат значительно лучше прошлого (**32.10632**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание № 5\n",
    "\n",
    "Итоговыми моделями постройте прогнозы для каждого конца истории от ***2016.05.31 23:00 до 2016.06.30 17:00*** и запишите все результаты в один файл в формате ***geoID, histEndDay, histEndHour, step, y***. Здесь ***geoID*** — идентификатор зоны, ***histEndDay*** — день конца истории в формате ***id***,***y***, где столбец ***id*** состоит из склеенных через подчёркивание идентификатора географической зоны, даты конца истории, часа конца истории и номера отсчёта, на который делается предсказание ***(1-6)***; столбец ***y*** — ваш прогноз."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение прогноза на контрольной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names =  [\"1. first_prediction\", \"2. second_prediction\", \"3. third_prediction\",\n",
    "               \"4. forth_prediction\", \"5. fifth_prediction\", \"6. sixth_prediction\"]\n",
    "for i in range(6):\n",
    "    encoded_data = encoder.transform(result_data[i][2][cat_attributes].T.to_dict().values())\n",
    "    cat_att = pd.DataFrame(encoded_data, columns=cat_columns)\n",
    "    cat_att.index = result_data[i][2].index\n",
    "\n",
    "    X_test = pd.concat([result_data[i][2][a], cat_att], axis=1)\n",
    "    \n",
    "    estimator = results[i][0]\n",
    "    prediction = estimator.predict(X_test)\n",
    "    res_shape = result_data[i][2][\"region\"].get_values().shape[0]\n",
    "    \n",
    "    prediction = pd.DataFrame(np.concatenate((result_data[i][2][\"region\"].get_values().reshape(res_shape, 1),\n",
    "                                              abs(prediction.astype(int)).reshape(res_shape, 1)),\n",
    "                                             axis=1),\n",
    "                              columns=[\"region\", \"trips\"])\n",
    "    \n",
    "    prediction.to_csv(\"new_result/\" + file_names[i] + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка массива дат для оформления результата."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta, datetime\n",
    "\n",
    "def daterange(date1, date2):\n",
    "    dates = []\n",
    "    for n in range(int((date2 - date1).days * 24)+ 19):\n",
    "        dates.append(date1 + timedelta(n / 24))\n",
    "    return dates\n",
    "\n",
    "start_dt = datetime(2016, 5, 31, 23)\n",
    "end_dt = datetime(2016, 6, 30, 17)\n",
    "dates = daterange(start_dt, end_dt)\n",
    "\n",
    "date_list = list(map(lambda date: np.repeat(date.strftime(\"_%Y-%m-%d_\") + str(date.hour) + \"_\", 102), dates))\n",
    "date_list = np.concatenate(date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72930, 2)\n",
      "(72930, 2)\n",
      "(72930, 2)\n",
      "(72930, 2)\n",
      "(72930, 2)\n",
      "(72930, 2)\n"
     ]
    }
   ],
   "source": [
    "file_path = np.sort(glob(\"new_result/*.csv\", recursive=True))\n",
    "solution_data = []\n",
    "for i in range(len(file_path)):\n",
    "    path = file_path[i]\n",
    "    result = pd.read_csv(path)[:len(dates * 102)]\n",
    "    solution_data.append(result)\n",
    "    print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохранение в необходимом формате для **Kaggle** данные прогнозов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = []\n",
    "for i in range(6):\n",
    "    res = solution_data[i]\n",
    "    regions = list(map(lambda reg: reg.split(\"_\")[1], solution_data[i][\"region\"]))\n",
    "\n",
    "    ids = []\n",
    "    for j in range(len(date_list)):\n",
    "        ids.append(regions[j] + date_list[j])\n",
    "    \n",
    "    res[\"id\"] = list(map(lambda _id: _id + str(i+1), ids))\n",
    "    res[\"y\"] = res.trips\n",
    "    solutions.append(res[[\"id\", \"y\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(solutions).sort_values(\"id\").to_csv(\"new_solution.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание № 6\n",
    "\n",
    "Загрузите полученный файл на kaggle: https://inclass.kaggle.com/c/yellowtaxi. Добавьте в ноутбук ссылку на сабмишн."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/submissions/6569525/6569525.zip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
