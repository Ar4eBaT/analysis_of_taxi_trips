{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных\n",
    "\n",
    "Скачайте сырые данные о поездках жёлтого такси с сайта [TLC](http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml)\n",
    "\n",
    "**Поездки зелёного такси и лимузинов нас не интересуют!**\n",
    "\n",
    "Данные выложены в файлах по месяцам. Скачайте так много данных жёлтого такси, как сможете; чем больше вы будете использовать данных, тем точнее получатся ваши прогнозы. Если вы решите использовать не все данные, а только часть, выбирайте её по времени с конца. Абсолютный минимум необходимых данных — 6 месяцев: один, последний месяц, вам понадобится для тестирования, предшествующие 5 — для обучения. По 5 месяцам можно построить прогнозы, учитывающие дневную и недельную сезонности, но в данных есть и годовая. Чтобы её учесть, необходимы данные как минимум за 2 года."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка данных\n",
    "\n",
    "Обработайте сырые данные по следующей схеме.\n",
    "\n",
    "1. Почистите данные от ошибок и аномалий.\n",
    "2. Отбросьте минуты и секунды во времени начала поездки.\n",
    "3. Нью-Йорк вписан в прямоугольник от **-74.25559** до **-73.70001** градусов долготы и от **40.49612** до **40.91553** широты. Разбейте этот прямоугольник на **2500** одинаковых прямоугольных областей — по **50** интервалов вдоль каждой оси.\n",
    "4. Посчитайте количество поездок за каждый час из каждой области. Не забудьте, что если в сырых данных для какой-то пары час-область нет ни одной записи, то в агрегированных данных для неё должен стоять 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В дальнейшем, когда вы будете предсказывать получившиеся ряды, нужно будет загружать ваши прогнозы на kaggle, поэтому нужно, чтобы идентификаторы ячеек были определены однозначно. В файле **regions.csv** даны идентификаторы ячеек, которые вам нужно использовать, и географические координаты их границ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сдачи задания этой недели вам нужно агрегировать только данные за **май 2016**, но, когда задание будет сдано, не забудьте запустить ваш агрегирующий скрипт на всех остальных месяцах, которые вы собираетесь использовать при прогнозировании."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных\n",
    "\n",
    "Загрузка данных за май 2016 года, и преобразование строк с датами и временем к типу **datetime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(name, state):\n",
    "    columns = []\n",
    "    if state == \"bad\":\n",
    "        columns = [\"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"passenger_count\",\n",
    "               \"trip_distance\", \"RatecodeID\", \"store_and_fwd_flag\", \"PULocationID\", \"DOLocationID\",\n",
    "               \"payment_type\", \"fare_amount\", \"extra\", \"mta_tax\", \"tip_amount\", \"tolls_amount\",\n",
    "               \"improvement_surcharge\", \"total_amount\", \"\", \"\"]\n",
    "    else:\n",
    "        columns = [\"vendor_id\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"passenger_count\",\n",
    "               \"trip_distance\", \"pickup_longitude\", 'pickup_latitude', \"rate_code\", \"store_and_fwd_flag\",\n",
    "               \"dropoff_longitude\", \"dropoff_latitude\", \"payment_type\", \"fare_amount\",\n",
    "               \"surcharge\", \"mta_tax\", 'tip_amount', \"tolls_amount\", \"total_amount\"]\n",
    "        \n",
    "    parse_dates = [\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"]\n",
    "    data = {\n",
    "    'normal': lambda name: pd.read_csv(\"data/\" + name, header=0,\n",
    "                   sep=\",\", parse_dates=parse_dates),\n",
    "    'bad': lambda name: pd.read_csv(\"data/\" + name, sep=\",\", names=columns,\n",
    "                   skiprows=1, parse_dates=parse_dates),\n",
    "    'old': lambda name: pd.read_csv(\"data/\" + name, skiprows=1,\n",
    "                   sep=\",\", parse_dates=parse_dates, names=columns)\n",
    "    }[state](name)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фильтрация данных\n",
    "\n",
    "Провести фильтрацию: удалить поездки с\n",
    "- нулевой длительностью\n",
    "- нулевым количеством пассажиров\n",
    "- нулевым расстоянием поездки по счётчику\n",
    "- координатами начала, не попадающими в прямоугольник Нью-Йорка\n",
    "\n",
    "Можно придумать ещё какие-то критерии для фильтрации данных; тем не менее, не стоит применять дополнительные фильтры: начиная с четвёртой недели вам предстоит сравнивать качество ваших прогнозов с качеством прогнозов других слушателей, и, чтобы это сравнение было корректным, нужно, чтобы данные у всех были предобработаны одинаково."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Фильтрация данных и отброс минут и секунд\n",
    "\n",
    "def filter_data(data, _type):\n",
    "    # Фильтрация данных с нулевой длительностью поездки\n",
    "    data = data[data.tpep_pickup_datetime != data.tpep_dropoff_datetime]\n",
    "    data = data[data.passenger_count != 0] # Фильтрация данных с нулевым количеством пассажиров\n",
    "    data = data[data.trip_distance != 0.0] # Фильтрация данных с нулевым расстоянием по счетчику\n",
    "    \n",
    "     # Отброс минут и секунд\n",
    "    data.tpep_pickup_datetime = map(lambda x: x.replace(minute=0, second=0), data.tpep_pickup_datetime)\n",
    "    \n",
    "    if _type == \"bad\":\n",
    "        return data\n",
    "    \n",
    "    # Фильтрация поездок, которые находятся за пределами Нью-Йорка\n",
    "    long_compare = (data.pickup_longitude >= -74.25559) & (data.pickup_longitude <= -73.70001)\n",
    "    lat_compare = (data.pickup_latitude >= 40.49612) & (data.pickup_latitude <= 40.91553)\n",
    "    data = data[long_compare & lat_compare]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Агрегация данных\n",
    "\n",
    "Агрегируйте данные за май 2016 года по часам и областям (можно использовать функцию stats.binned_statistic_2d, с которой вы сталкивались в заданиях четвёртого курса). Не забудьте проверить, что идентификаторы, которые вы присваиваете ячейкам, соответствуют приложенному выше файлу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import binned_statistic_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обёртка для функции binned_statistic_2d, для получения более точного номера области,\n",
    "# в соответствии с приложенным к заданию файлом\n",
    "\n",
    "def bin_stats(input_data):\n",
    "    s, x_edge, y_edge, binnumber = binned_statistic_2d(input_data.pickup_longitude,\n",
    "                                                   input_data.pickup_latitude,\n",
    "                                                   None, statistic='count', bins=50,\n",
    "                                                   range=[[-74.25559, -73.70001], [40.49612, 40.91553]],\n",
    "                                                  expand_binnumbers=True)\n",
    "    return s, x_edge, y_edge, 50 * (binnumber[0] - 1) + binnumber[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import calendar\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def date_num_from_name(name):\n",
    "    text = name.replace(\"_\", \" \").replace(\"-\", \" \").replace(\".\", \" \")\n",
    "    digit_array = [int(s) for s in text.split() if s.isdigit()]\n",
    "    year = digit_array[0]\n",
    "    month = digit_array[1]\n",
    "    return year, month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Создание пустой таблицы со всеми возможными значениями времени и регионов\n",
    "\n",
    "def create_empty_frame(name):\n",
    "    year, month = date_num_from_name(name)\n",
    "    days = calendar.monthrange(year, month)[1]\n",
    "    regions = range(1, 2501)\n",
    "    start_date = str(month) + '/1/' + str(year)\n",
    "    date = pd.date_range(start_date, periods=days*24, freq='H')\n",
    "    agg_data = map(lambda x: (x[0], x[1]), itertools.product(regions, date))\n",
    "    agg_data = pd.DataFrame(agg_data, columns = ['region', 'time'])\n",
    "    return agg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_agg_data(agg_data, data):\n",
    "    # Получение количества поездок по области и времени заказа\n",
    "    reg_trips = data[[\"region\", \"tpep_pickup_datetime\", \"trip_distance\"]].groupby([\"region\", \"tpep_pickup_datetime\"], as_index=False).count()\n",
    "    reg_trips.columns = [\"region\", \"time\", \"trips\"]\n",
    "    \n",
    "    # Набор агрегированных данных по областям и временем поездок на жёлтом такси\n",
    "    agg_data = pd.merge(agg_data, reg_trips, how='left').fillna(0)\n",
    "    return agg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Весь отработанный процесс фильтрации, агрегации и сохранение данных\n",
    "\n",
    "def aggregate_data(name, _type):\n",
    "    flag = {\n",
    "        'bad': True,\n",
    "        'normal': True,\n",
    "        'old': True\n",
    "    }.get(_type, False)\n",
    "    \n",
    "    if flag is False:\n",
    "        print \"Set _type is normal, bad or old\"\n",
    "        return\n",
    "    \n",
    "    data = read_data(name, _type)\n",
    "    data = filter_data(data, _type)\n",
    "    \n",
    "    if _type != \"bad\":\n",
    "        s, x_edge, y_edge, regions = bin_stats(data)\n",
    "        data[\"region\"] = regions\n",
    "    else:\n",
    "        data[\"region\"] = data[\"PULocationID\"]\n",
    "    \n",
    "    agg_data = create_empty_frame(name)\n",
    "    agg_data = merge_agg_data(agg_data, data)\n",
    "    \n",
    "    # Сохранение нового представления данных о поездках в csv\n",
    "    agg_data.to_csv(\"u_data/\" + name, sep=\",\", index=False)\n",
    "    \n",
    "    os.remove(\"data/\" + name)\n",
    "    return agg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте график количества поездок жёлтого такси из ячейки, содержащей Empire State Building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>west</th>\n",
       "      <th>east</th>\n",
       "      <th>south</th>\n",
       "      <th>north</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-74.25559</td>\n",
       "      <td>-74.244478</td>\n",
       "      <td>40.496120</td>\n",
       "      <td>40.504508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-74.25559</td>\n",
       "      <td>-74.244478</td>\n",
       "      <td>40.504508</td>\n",
       "      <td>40.512896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-74.25559</td>\n",
       "      <td>-74.244478</td>\n",
       "      <td>40.512896</td>\n",
       "      <td>40.521285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-74.25559</td>\n",
       "      <td>-74.244478</td>\n",
       "      <td>40.521285</td>\n",
       "      <td>40.529673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-74.25559</td>\n",
       "      <td>-74.244478</td>\n",
       "      <td>40.529673</td>\n",
       "      <td>40.538061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   region      west       east      south      north\n",
       "0       1 -74.25559 -74.244478  40.496120  40.504508\n",
       "1       2 -74.25559 -74.244478  40.504508  40.512896\n",
       "2       3 -74.25559 -74.244478  40.512896  40.521285\n",
       "3       4 -74.25559 -74.244478  40.521285  40.529673\n",
       "4       5 -74.25559 -74.244478  40.529673  40.538061"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions = pd.read_csv(\"regions.csv\", sep=\";\")\n",
    "regions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_edge = pd.unique(np.concatenate((regions.west, regions.east)))\n",
    "y_edge = pd.unique(np.concatenate((regions.south, regions.north)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empire State Building located in 1231 region.\n"
     ]
    }
   ],
   "source": [
    "# Нахождение области, в котором находится Empire State Building по заранее известным координатам\n",
    "\n",
    "x = -73.985428\n",
    "y = 40.748817\n",
    "\n",
    "x_num = 0\n",
    "for i in xrange(len(x_edge) - 1):\n",
    "    if x >= x_edge[i] and x <= x_edge[i + 1]:\n",
    "        x_num = i;\n",
    "        break\n",
    "    \n",
    "y_num = 0\n",
    "for i in xrange(len(y_edge) - 1):\n",
    "    if y >= y_edge[i] and y <= y_edge[i + 1]:\n",
    "        y_num = i;\n",
    "        break\n",
    "\n",
    "reg_index = 50 * x_num + y_num + 1\n",
    "print \"Empire State Building located in %d region.\" % (reg_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Почасовая отчетность по поездкам в данной области\n",
    "esb_reg_data = agg_data[agg_data.region == reg_index]\n",
    "print esb_reg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pylab.figure(figsize=(14,8))\n",
    "pylab.plot(esb_reg_data.time, esb_reg_data.trips)\n",
    "pylab.title(\"Empire State Building trips\", fontweight='bold')\n",
    "pylab.xlabel(\"Time\", fontweight='bold')\n",
    "pylab.ylabel(\"Trips\", fontweight='bold')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитайте, сколько в мае 2016 было пар час-ячейка, для которых не было совершено ни одной поездки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zeros_pair = agg_data[agg_data.trips == 0].shape[0]\n",
    "all_values = agg_data.shape[0]\n",
    "print \"%d out of %d pairs hour-region do not have trips\" % (zeros_pair, all_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка остальных данных\n",
    "\n",
    "Получение списка всех файлов с данными о поездках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yellow_tripdata_2009-01.csv',\n",
       " 'yellow_tripdata_2009-02.csv',\n",
       " 'yellow_tripdata_2009-03.csv',\n",
       " 'yellow_tripdata_2009-04.csv',\n",
       " 'yellow_tripdata_2009-05.csv',\n",
       " 'yellow_tripdata_2009-06.csv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "data_list = os.listdir(\"data\")\n",
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin...\n",
      "yellow_tripdata_2009-01.csv is complete!\n",
      "yellow_tripdata_2009-02.csv is complete!\n",
      "yellow_tripdata_2009-03.csv is complete!\n",
      "yellow_tripdata_2009-04.csv is complete!\n",
      "yellow_tripdata_2009-05.csv is complete!\n",
      "yellow_tripdata_2009-06.csv is complete!\n",
      "...End\n"
     ]
    }
   ],
   "source": [
    "print \"Begin...\"\n",
    "for fname in data_list:\n",
    "    aggregate_data(fname, \"old\")\n",
    "    print fname + \" is complete!\"\n",
    "print \"...End\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
